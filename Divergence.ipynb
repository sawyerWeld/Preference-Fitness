{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kullback-Leibler Divergence of Empirical and Theoretical Probabilities of Rankings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Kullback-Leibler(KL) divergence of two probability distributions is a measure of difference between the two probability distributions. For probability distributions E and T, the KL divergence is \n",
    "\n",
    "$$ D_{KL}(P, Q) = \\sum_{i}Q(i)\\log\\frac{Q(i)}{P(i)}    $$\n",
    "\n",
    "where i is the ith term that the probability distribution is defined over. To find the KL divergence between the empirical and theoretical probability distributions of the Ireland 2002 data, we first load in the data as well as the parameters we found for the Mallows and Plackett-Luce models that best fit the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([3, 1, 2, 4]), 0.017524902443235235],\n",
       " array([0.39292042, 0.08434978, 0.40365703, 0.11907276]),\n",
       " 475.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import readPreflib\n",
    "import numpy as np\n",
    "\n",
    "_, lengths, votes = readPreflib.soiInputwithWeights('data_input/ED-debian-2002.soi')\n",
    "num_votes = 1.0 * sum(lengths.values())\n",
    "\n",
    "import pickle\n",
    "\n",
    "mallows_params  = pickle.load( open('pickle/mallows2002_100k.p','rb') )\n",
    "sigma, phi = mallows_params\n",
    "plackett_params = pickle.load( open('pickle/plackett2002_100k.p','rb')) \n",
    "pl_weights = plackett_params\n",
    "\n",
    "mallows_params, plackett_params, num_votes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to gather the probability functions for the Mallows and Plackett-Luce models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Mallows_Notebook.ipynb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1ff6f2a21d14365b285746fa79d3673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=100000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import Mallows_Notebook\n",
    "import PL_Notebook\n",
    "import math\n",
    "\n",
    "divergence_mallows = 0\n",
    "divergence_plackett = 0\n",
    "for entry in votes:\n",
    "    num_occurances, vote = entry\n",
    "    empirical = num_occurances / num_votes\n",
    "    mallows = Mallows_Notebook.mallowsProb(vote, sigma, phi)\n",
    "    plackett = PL_Notebook.probPlackett(vote, pl_weights)\n",
    "    divergence_mallows += insideSum(mallows, empirical)\n",
    "    divergence_plackett += insideSum(plackett, empirical)\n",
    "    \n",
    "def insideSum(Qi,Pi):\n",
    "    return Qi * math.log(Qi/Pi)\n",
    "\n",
    "divergence_mallows, divergence_plackett"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
